{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing PDF\n",
    "preprocessing a pdf to textfile. Then combining n lines to create a list of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import os\n",
    "\n",
    "user_file = 'Main_Reference.pdf'\n",
    "if user_file.endswith('.pdf'):\n",
    "    pdfFileObj = open(user_file, 'rb')\n",
    "    pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "    x = len(pdfReader.pages)\n",
    "\n",
    "    if os.path.isfile('processedTextFile.txt'):\n",
    "        os.remove('processedTextFile.txt')\n",
    "        \n",
    "    for y in range(x):\n",
    "        pageObj = pdfReader.pages[y]\n",
    "        text = pageObj.extract_text()\n",
    "        with open('processedTextFile.txt', 'a') as f:\n",
    "            f.write(text)\n",
    "    user_file = 'processedTextFile.txt'\n",
    "        \n",
    "\n",
    "pdfdoc = open(user_file, 'r').read().replace('\\n', '')\n",
    "pdfdoc = re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', pdfdoc)\n",
    "sequences = list() # list to store multiple lines as sequence\n",
    "n_sentence = 4\n",
    "for i in range(0,len(pdfdoc), n_sentence):\n",
    "    sequences.append(' '.join(pdfdoc[i:i+n_sentence]))\n",
    "# sequences = list(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This might be as a result of the orientation of the captured fingerprint images. The fingerprints were captured using various angles of the scanner, as it depends on where the subject stands before the scanner for capturing. Moreover, 833 right hands were correctly classified, with 92.56% overall classification rate,where 67 right hands were wrongly misclassified as left hands. In Table III, individual subject s’fingers are classified with an overall accuracy of 76.72%.\n"
     ]
    }
   ],
   "source": [
    "print(sequences[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csa/miniconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0110,  0.0994, -0.0149,  ..., -0.1003, -0.0117, -0.0279],\n",
      "        [ 0.1471,  0.2742,  0.0348,  ..., -0.3416,  0.0040,  0.0922],\n",
      "        [ 0.0233,  0.3932,  0.0820,  ...,  0.1234,  0.3126,  0.0336],\n",
      "        ...,\n",
      "        [ 0.0501,  0.0220,  0.0967,  ..., -0.1937,  0.2379,  0.2083],\n",
      "        [-0.0063,  0.0939, -0.0430,  ..., -0.1464, -0.0137, -0.0600],\n",
      "        [-0.0034,  0.1189, -0.0209,  ..., -0.0830,  0.0084,  0.0249]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "vectors = [\n",
    "    # tokenize the sequence, return it as PyTorch tensors (vectors),\n",
    "    # and pass it onto the model\n",
    "    model(**tokenizer(sequence, return_tensors='pt'))[0].detach().squeeze()\n",
    "    for sequence in sequences\n",
    "]\n",
    "print(vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def encode(document: str) -> torch.Tensor:\n",
    "    tokens = tokenizer(document, return_tensors='pt')\n",
    "    vector = model(**tokens)[0].detach().squeeze()\n",
    "    return torch.mean(vector, dim=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top K similar Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "averaged_vectors = [torch.mean(vector, dim=0) for vector in vectors]\n",
    "\n",
    "v_size = [v.size() for v in averaged_vectors][0][0]\n",
    "index = faiss.IndexIDMap(faiss.IndexFlatIP(v_size)) # the size of our vector space\n",
    "# index all the documents, we need them as numpy arrays first\n",
    "index.add_with_ids(\n",
    "    np.array([t.numpy() for t in averaged_vectors]),\n",
    "    # the IDs will be 0 to len(documents)\n",
    "    np.array(range(0, len(sequences)))\n",
    ")\n",
    "\n",
    "def search(query: str, k=1):\n",
    "    encoded_query = encode(query).unsqueeze(dim=0).numpy()\n",
    "    top_k = index.search(encoded_query, k)\n",
    "    scores = top_k[0][0]\n",
    "    results = [sequences[_id] for _id in top_k[1][0]]\n",
    "    return list(zip(results, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 165.63258361816406\n",
      "Text:\n",
      "And it has been proven by many researchers that fingerprints can be used for gender classification, which is helpful when short-listing suspects [4-7]. The uniqueness of the fingerprint features can reduce the gender identification difficulties and limit the amount of time it takes to identify a suspect. These unique features of fingerprints can be used in differentiating between individualsby their gender and, therefore, it makes faster theidentification processes of unknown suspects. Furthermore, itcan guide forensic investigators to the correct identity of a suspect when matching the suspect’s fingerprints among the large number of possible matches in the fingerprint databases.It is extremely time consuming to identify and detect unknown fingerprints in a large volume of fingerprint databases during investigation.\n",
      "Similarity score: 165.5492401123047\n",
      "Text:\n",
      "Similarly, for hand identification, there are 3000 images from left hands and 3000 from right hands. All of these images are used for hand identification; and this subset is referred to as SOCOFing- Hands. Lastly, SOCOFing also contains an even number of images for each individual finger: 600 images for each of the 10 fingers. These images are used for finger identification and, since it includes all images from the corpus, it is simply referred to as SOCOFing.\n",
      "Similarity score: 164.9171142578125\n",
      "Text:\n",
      "Features of the fingerprintsstatistically differ between genders and age categories [2]. Personal identification is es sential in security and video surveillance applications. An individual can be recognized by various features, such as body, voice, stature, and shape.Gender is one of the most essential features that separates between people. Fingerprinting is considered the best technique for distinguishing between individuals and for tracking criminals [3].\n"
     ]
    }
   ],
   "source": [
    "with open('userstring.txt', 'r') as f:\n",
    "    user_text = f.read()\n",
    "    \n",
    "results = search(user_text, k=3)\n",
    "for result in results:\n",
    "    print(f'Similarity score: {result[1]}\\nText:')\n",
    "    print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
